---
title: 'Trees and Forests Assignment'
author: "STUDENT NAME"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load the libraries + functions

Load all the libraries or functions that you will use to for the rest of the assignment. It is helpful to define your libraries and functions at the top of a report, so that others can know what they need for the report to compile correctly.

The data for this project has already been loaded. You will be distinguishing between the categories of *nerd* and *geek* to determine the influence of respective variables on their category definition. 

If you are having trouble with the `Rling` library - the nerd data is avaliable on Canvas, and you can load it directly. 

```{r libraries}
##r chunk
library(Rling)
library(reticulate)
library(party)
use_condaenv("py35_env")
data(nerd)
head(nerd)
```

## Description of the data

Dependent variable: 

- Noun: which category is represented either *nerd* or *geek*.

Independent variables:

- Num: a measure of social group, either pl (plural) or sg (single)
- Century: time measurement, as XX (20th) or XXI (21st) century
- Register: information about where the data was coded from ACAD (academic), MAG (magazine), NEWS (newspapers), and SPOK (spoken)
- Eval: A measure of the semanticity of the word, Neg for negative, Neutral, and Positive

## Conditional inference model

- Add a random number generator to start the model.
- Use `ctree()` to create a conditional inference model. 

```{r cimodel}
##r chunk
#start with a random number generator
set.seed(123456)

#generate a tree
tree.output = ctree(Noun ~ Num + Century + Register + Eval, data = nerd)
```

## Make a plot

- Plot the conditional inference model. 

```{r ciplot}
##r chunk
plot(tree.output)
```

## Interpretation consideration 

- Tree includes all possible splits that were significant at p < .05
- Ovals are the names of the variables with the best split
- The splits are shown on the branches
- Bottom bar chart helps show the number of DV instances in each split

## Interpretation

- With only two categories, you will see the proportion split as the output in the bar graph - look for the group with the larger proportion. 
- It's first split by evaluation and then by the century the data was recorded.
- The bar shows the positive eval are better in predicting the geek categories, etc.




## Conditional inference model predictiveness

- Calculate the percent correct classification for the conditional inference model. 

```{r cicorrect}
##r chunk
##r chunk
outcomes = table(predict(tree.output), nerd$Noun)
outcomes
```

## Random forests

- Create a random forest of the same model for geek versus nerd. 

```{r forestmodel}
##r chunk
forest.output = cforest(Noun ~ Num + Century + Register + Eval, data = nerd,
                        controls = cforest_unbiased(ntree = 1000,mtry = 2))

```

## Variable importance

- Calculate the variable importance from the random forest model.
- Include a dot plot of the importance values. 
- Which variables were the most important?

```{r forestimportance}
##r chunk
forest.importance = varimp(forest.output,conditional = T)
round(forest.importance, 3)
dotchart(sort(forest.importance), main = "Conditional Importance of Variables")
```
Eval is the most important.

## Forest model predictiveness

- Include the percent correct for the random forest model. 
- Did it do better than the conditional inference tree?

```{r forestpredict}
##r chunk
forest.outcomes = table(predict(forest.output), nerd$Noun)
forest.outcomes
sum(diag(forest.outcomes)) / sum(forest.outcomes) * 100
```
CI model is better.

## Python model

```{r}
py_config()
py_module_available("sklearn") #make sure sklearn is installed
```


- In this section, import the data from R to Python.
- Be sure to convert the categorical data into dummy coded data. 

```{python data_import}
##python chunk
import pandas as pd

Xvars = pd.get_dummies(r.nerd[["Num", "Century", "Register", "Eval"]])
Xvars.head()
Yvar = pd.get_dummies(r.nerd["Noun"])
Yvar.head()
```

## Create the Tree

- Create a decision tree classification of the `nerd` data. 

```{python decision_tree}
##python chunk
import sklearn
from sklearn import tree
# create the tree as your classifier
CIT = tree.DecisionTreeClassifier()

# fit it to the data
CIT = CIT.fit(Xvars, Yvar)
```

## Printing out the Tree

- Print out a text version of the classification tree. 

```{python class_tree}
##python chunk
#check out graph viz if you want other printing options
print(tree.export_text(CIT, feature_names = list(Xvars.columns)))
```

## Confusion Matrix

```{python confusion_matrix}
##python chunk
Y_predict = pd.DataFrame(CIT.predict(Xvars))
Y_predict.columns = list(Yvar.columns)
Y_predict_category = Y_predict.idxmax(axis=1)
Yvar_category = Yvar.idxmax(axis=1)

sklearn.metrics.confusion_matrix(Y_predict_category, Yvar_category, labels=["geek", "nerd"])
```

```{r}
outcomes
```


## Thought questions

- Are the models easier to create using R or Python (your own thoughts, they can be different than what I said in the lecture)?
It's easier in R definitely.
- Which model gave you a better classification of the categories?
Tree model in R has the best performance.
- What other variables might be useful in understanding the category membership of geek versus nerd? Basically, what could we add to the model to improve it (there's no one right answer here - it's helpful to think about what other facets we have not measured)?
I believe it would be helpful to have subject matter of data for example computers, science, arts, music etc.

  